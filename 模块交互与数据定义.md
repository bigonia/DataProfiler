好的，我们来将之前的《数据结构与流转详解》扩展为一份更全面的《模块交互与数据定义文档》。这份文档将重点描述系统内部模块之间的交互顺序、关键参数以及它们交换的数据契约，并辅以流程图来说明。

-----

### **模块交互与数据定义文档**

#### **1. 概述**

本文档旨在详细阐述“智能数据剖析与处理平台”中，一次典型的数据剖析任务从发起到完成的端到端数据流转和模块交互过程。它将清晰地定义系统核心模块之间的调用关系、关键的输入输出参数，并给出在交互过程中使用的数据结构（数据契约）的精确定义。

本文档是系统设计和开发的核心依据，旨在确保各模块开发团队对数据流和数据结构有统一、无歧义的理解。

#### **2. 核心模块职责**

在深入流程之前，首先明确各个核心服务/模块的职责：

  * **`API Controller`**: 系统的HTTP入口，负责接收外部API请求，校验参数，并调用相应的应用服务。
  * **`ProfilingService`**: **核心业务编排器**。负责接收剖析任务请求，创建和管理任务生命周期，调度`Profiler`进行数据获取，并调用`ReportAssemblyService`进行数据加工。
  * **`DataSourceService`**: 负责管理数据源的配置信息，提供根据`dataSourceId`查询详细连接配置的功能。
  * **`IDatabaseProfiler`**: **数据获取执行器**的接口。其具体实现（如`MySqlProfiler`, `SqliteProfiler`）封装了与特定数据库方言的交互逻辑和自适应剖析策略。
  * **`ReportAssemblyService`**: **数据加工厂**。负责将原始的、未加工的剖析数据，丰富化为包含派生指标和高级统计的、对用户友好的最终报告。
  * **`StructuredReportService`**: **报告仓储服务**。负责将最终生成的分析报告进行持久化存储和对外提供查询服务。

#### **3. 核心交互流程：剖析任务的生命周期**

以下将通过时序流程图的方式，详细描述一次（单源或多源）剖析任务的完整生命周期。

```mermaid
sequenceDiagram
    participant Client as API客户端
    participant Controller as API Controller
    participant ProfilingService as 剖析服务
    participant DataSourceService as 数据源服务
    participant Profiler as IDatabaseProfiler
    participant AssemblyService as 报告组装服务
    participant ReportService as 报告仓储服务

    %% 1. 发起任务
    Client->>+Controller: POST /profiling-tasks (携带 ProfilingTaskRequest)
    Controller->>+ProfilingService: executeProfilingTask(request)
    ProfilingService-->>-Controller: TaskStatusResponse (含 taskId, status: PENDING)
    Controller-->>-Client: 202 Accepted (返回 TaskStatusResponse)

    %% 2. 异步执行任务
    Note over ProfilingService: 开始异步处理任务 (taskId)
    ProfilingService->>+DataSourceService: getDataSourceConfig(dataSourceId)
    DataSourceService-->>-ProfilingService: 返回 DataSourceConfig

    %% 3. 数据获取
    ProfilingService->>+Profiler: profile(config)
    Note over Profiler: 执行自适应策略<br/>与源数据库交互<br/>执行SQL查询
    Profiler-->>-ProfilingService: 返回 RawProfileDataDto

    %% 4. 数据组装
    ProfilingService->>+AssemblyService: assemble(RawProfileDataDto)
    Note over AssemblyService: 计算派生指标<br/>基于样本进行高级计算<br/>转换数据结构
    AssemblyService-->>-ProfilingService: 返回 StructuredReportDto

    %% 5. 报告持久化与任务状态更新
    ProfilingService->>+ReportService: saveReport(taskId, report)
    ReportService-->>-ProfilingService: 持久化成功
    Note over ProfilingService: 更新任务状态为 SUCCESS
```

**流程步骤详解：**

**步骤 1: 发起剖析任务 (Initiate Profiling Task)**

  * **交互**: `API客户端`向`API Controller`的`POST /profiling-tasks`端点发起请求。
  * **关键参数/载荷**: `ProfilingTaskRequest` 对象，其中定义了需要剖析的一个或多个数据源及其范围。
  * **处理**: `ProfilingService`接收到请求后，立即创建一个任务记录，生成唯一的`taskId`，将初始状态设置为`PENDING`，并将此`TaskStatusResponse`（包含`taskId`和状态）同步返回给客户端。整个过程响应迅速，客户端不会被长时间阻塞。

**步骤 2: 任务执行与数据源信息获取 (Task Execution & Config Fetching)**

  * **交互**: `ProfilingService`在一个**异步线程**中开始处理该`taskId`对应的任务。
  * **处理**:
    1.  它首先根据请求中的`dataSourceId`，调用`DataSourceService`获取每个数据源详细的连接信息和配置（`DataSourceConfig`）。
    2.  根据`DataSourceConfig`中的`type`字段，实例化一个对应的`IDatabaseProfiler`实现（例如，`PostgreSqlProfiler`）。

**步骤 3: 数据获取与原始剖析 (Data Acquisition & Raw Profiling)**

  * **交互**: `ProfilingService`调用选定的`Profiler`实例的`profile()`方法。
  * **关键参数/载荷**:
      * **传入**: `DataSourceConfig`对象。
      * **返回**: `RawProfileDataDto`对象。
  * **处理**: 这是与源数据库交互的核心步骤。`Profiler`内部会执行“自适应剖析策略”，通过预检决定是执行精确查询还是近似查询，最终将所有直接获取到的元数据和基础指标封装到`RawProfileDataDto`中返回。

**步骤 4: 数据组装与丰富化 (Data Assembly & Enrichment)**

  * **交互**: `ProfilingService`将上一步获取的`RawProfileDataDto`传递给`ReportAssemblyService`的`assemble()`方法。
  * **关键参数/载荷**:
      * **传入**: `RawProfileDataDto`。
      * **返回**: `StructuredReportDto`。
  * **处理**: `ReportAssemblyService`对原始数据进行深度加工，计算出平均值、标准差、各种比率等派生和高级指标，并按照最终报告的格式进行组装。

**步骤 5: 报告持久化与任务完成 (Report Persistence & Task Completion)**

  * **交互**: `ProfilingService`将最终生成的`StructuredReportDto`交给`StructuredReportService`进行持久化。
  * **处理**: `StructuredReportService`将报告存入SQLite数据库。持久化成功后，`ProfilingService`将该`taskId`对应的任务状态更新为`SUCCESS`。如果任何步骤出现异常，状态将被更新为`FAILED`。

#### **4. 核心数据结构定义**

##### **4.1. 数据获取阶段产出：`RawProfileDataDto`**

  * **角色**: 内部“原始物料”，由`Profiler`生成，供`AssemblyService`消费。

**结构定义 (JSON with Comments):**

```json
[
  // 这是一个表的集合，每个对象代表一张被剖析的表
  {
    "schemaName": "public", // 表所属的Schema（模式）名称
    "tableName": "orders", // 表名
    "rowCount": 1500000,   // 表的总行数 (可能为估算值)
    "comment": "销售订单核心表", // 表注释
    "columns": [
      // 列的集合，只包含基础元数据和指标
      {
        "columnName": "order_id",    // 列名
        "columnType": "INTEGER",   // 列的原生数据类型
        "isPrimaryKey": true,      // 是否为主键的一部分
        "comment": "订单的唯一标识符"
      },
      {
        "columnName": "order_amount",
        "columnType": "NUMERIC(10, 2)",
        "isPrimaryKey": false,
        "comment": "订单总金额",
        "range": { // 仅在数值、日期等可比较类型上返回
          "min": 0.50,
          "max": 9999.99
        }
      }
    ]
  }
]
```

##### **4.2. 数据组装阶段产出：`StructuredReportDto`**

  * **角色**: 最终“成品”报告，由`AssemblyService`生成，供持久化和API查询。

**结构定义 (JSON with Comments):**

```json
{
  "dataSourceId": "ds-pg-01",
  "dataSourceType": "POSTGRESQL",
  "database": {
    "name": "sales_dw"
  },
  "tables": [
    // 表的集合，信息得到了极大的丰富
    {
      "name": "orders",
      "schemaName": "public",
      "rowCount": 1500000,
      "comment": "销售订单核心表",
      "columns": [
        // 列的集合，扩展了包含二次计算指标的 metrics 字段
        {
          "name": "order_amount",
          "type": "NUMERIC(10, 2)",
          "isPrimaryKey": false,
          "comment": "订单总金额",
          "metrics": {
            // "metrics" 对象包含了所有计算得出的详细指标
            "nullCount": 50,
            "nullRate": 0.000033,       // (二次计算)
            "distinctCount": 12800,
            "distinctRate": 0.00853,    // (二次计算)
            "range": {
              "min": 0.50,
              "max": 9999.99
            },
            "avg": 125.75,              // (二次计算)
            "stddev": 89.5,             // (二次计算)
            "minLength": 4,             // (二次计算, 针对字符串)
            "maxLength": 12             // (二次计算, 针对字符串)
          }
        }
      ]
    }
  ]
}
```