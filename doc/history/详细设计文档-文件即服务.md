### **详细设计文档 - 文件即服务 (FileAsTableService)**

#### **1. 模块概述**

**1.1. 核心职责**

`FileAsTableService` 是平台数据源系统的重要组成部分，负责将文件类数据源（Excel、CSV等）转换为标准的数据库表结构，使其能够无缝融入到统一的数据剖析流程中。其核心职责包括：

  * **文件数据转换**: 将Excel文件的每个Sheet和CSV文件转换为SQLite数据库表
  * **数据源适配**: 作为适配器模式的实现，将非结构化文件数据"数据库化"
  * **统一接口支持**: 使文件数据源能够通过标准的`IDatabaseProfiler`接口进行剖析
  * **元数据管理**: 维护文件到表的映射关系，支持Sheet名称到表名的转换

该服务是平台处理异构数据源能力的关键一环，确保了文件数据源与传统数据库数据源在剖析流程中的一致性。

**1.2. 系统集成**

在当前系统架构中，`FileAsTableService`与以下组件协作：

  * **数据源系统**: 与`DataSourceService`协作，创建`FILE`类型的数据源配置
  * **任务系统**: 支持`ProfilingService`对文件数据源的统一调度和管理
  * **剖析系统**: 通过`SqliteProfiler`实现对转换后表结构的标准化剖析
  * **核心存储**: 直接操作平台核心SQLite数据库，确保数据持久化

**1.3. 主要接口与API**

  * **服务接口**: `com.dataprofiler.service.FileAsTableService`
  * **实现类**: `com.dataprofiler.service.impl.FileAsTableServiceImpl`
  * **API入口**: `com.dataprofiler.controller.FileController`

#### **2. 系统架构设计**

**2.1. 数据源系统设计**

数据源系统采用统一的`DataSourceConfig`实体管理所有类型的数据源，支持以下类型：

  * **传统数据库**: MySQL、PostgreSQL、Oracle、SQL Server等
  * **文件数据源**: Excel、CSV等文件类型
  * **其他数据源**: 可扩展支持更多数据源类型

核心特性：
  * **统一配置模型**: 所有数据源共享相同的配置结构和生命周期管理
  * **类型适配**: 通过`DataSourceType`枚举区分不同数据源类型
  * **连接管理**: 提供统一的连接测试和验证机制
  * **元数据缓存**: 支持数据源元数据的缓存和更新

**2.2. 任务系统设计**

任务系统基于`ProfilingTask`实体，支持多数据源的统一调度和管理：

  * **多数据源支持**: 单个任务可以包含多个数据源，支持批量处理
  * **异步执行**: 采用异步模式执行长时间运行的剖析任务
  * **状态管理**: 完整的任务状态跟踪（PENDING、RUNNING、COMPLETED、FAILED等）
  * **进度监控**: 实时跟踪任务执行进度和数据源处理状态
  * **错误处理**: 支持单个数据源失败时的任务继续执行

**2.3. 剖析过程设计**

剖析过程采用策略模式和工厂模式，实现了高度可扩展的数据剖析架构：

**核心组件**：
  * **IDatabaseProfiler接口**: 定义统一的剖析接口规范
  * **具体Profiler实现**: 针对不同数据源类型的专门实现
  * **ProfilerFactory**: 根据数据源类型自动选择合适的Profiler
  * **自适应策略**: 根据数据量和复杂度选择精确或近似查询策略

**剖析流程**：
1. **元数据预检**: 获取数据源的基本信息（表、列、索引等）
2. **策略决策**: 基于数据量和查询复杂度选择剖析策略
3. **数据采样**: 执行统计查询，收集数据质量指标
4. **结果组装**: 将原始剖析数据转换为标准化的报告格式
5. **持久化**: 将剖析结果保存到报告系统

#### **3. 文件数据源兼容性实现**

**3.1. 统一剖析接口支持**

为了使文件数据源能够无缝融入现有的剖析流程，系统实现了以下兼容性机制：

**SqliteProfiler扩展**：
  * **FILE类型识别**: `SqliteProfiler`能够识别`DataSourceType.FILE`类型的数据源
  * **动态表发现**: 对于FILE类型数据源，返回实际的Excel Sheet表而非SQLite系统表
  * **元数据适配**: 将文件表的元数据转换为标准的数据库表元数据格式
  * **连接复用**: 复用现有的SQLite连接管理机制

**数据源配置统一**：
  * **配置标准化**: FILE类型数据源使用相同的`DataSourceConfig`结构
  * **连接字符串**: 使用标准的`jdbc:sqlite:data/core.db`连接字符串
  * **认证机制**: 文件数据源无需额外的认证配置

**3.2. 功能扩展机制**

**文件类型扩展**：
  * **解析器接口**: 可扩展支持更多文件格式（JSON、XML、Parquet等）
  * **类型检测**: 基于文件扩展名和内容自动识别文件类型
  * **转换策略**: 不同文件类型采用相应的解析和转换策略

**数据类型映射**：
  * **智能推断**: 基于数据内容自动推断最适合的SQLite数据类型
  * **类型转换**: 支持Excel数值、日期、文本等类型到SQLite类型的转换
  * **空值处理**: 统一的空值和异常数据处理机制

**性能优化**：
  * **批量插入**: 使用批量插入提高大文件的加载性能
  * **内存管理**: 流式处理避免大文件导致的内存溢出
  * **索引创建**: 自动为主要列创建索引以提高查询性能

#### **4. 接口定义 (Java Interface)**

```java
package com.dataprofiler.service;

import com.dataprofiler.dto.FileLoadResult;
import com.dataprofiler.entity.DataSourceConfig;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;

public interface FileAsTableService {

    /**
     * 处理上传的Excel文件，将其内容解析并加载到核心SQLite数据库中。
     * @param file 上传的文件对象。
     * @param dataSourceName 用户为该文件数据源指定的名称。
     * @return 包含加载结果信息的DTO，如生成的dataSourceId和每个Sheet对应的表信息。
     * @throws IOException 文件读取或解析异常。
     */
    FileLoadResult loadExcelFileToDatabase(MultipartFile file, String dataSourceName) throws IOException;

}
```

#### **3. 核心流程与实现逻辑**

`loadExcelFileToDatabase`方法的内部执行逻辑如下：

1.  **文件校验 (Validation)**:

      * 检查`file`对象是否为空，文件大小是否超限。
      * 校验文件的`ContentType`或文件名后缀，确保是支持的Excel格式（如`.xlsx`, `.xls`）。

2.  **创建数据源记录 (Create DataSource Entry)**:

      * 在处理文件内容之前，首先为这个上传的文件创建一个`DataSourceConfig`记录。
      * 调用`DataSourceService.createDataSource()`，传入一个`type`为`FILE`的对象，并包含文件名、大小、MIME类型等元数据。
      * 此操作会生成一个唯一的`dataSourceId`，这个ID将作为后续生成表名的重要前缀。

3.  **解析Excel文件 (Parse Excel File)**:

      * 使用**Apache POI**库的`WorkbookFactory.create(file.getInputStream())`来打开Excel工作簿。此方法能自动兼容`HSSF` (.xls) 和`XSSF` (.xlsx) 两种格式。

4.  **遍历Sheet并创建表 (Iterate Sheets & Create Tables)**:

      * 使用`for-each`循环遍历`Workbook`中的每一个`Sheet`。
      * **对于每个Sheet**:
        a. **生成表名 (Generate Table Name)**:
        \* 获取Sheet的名称（如 "Q1-Sales"）。
        \* 对Sheet名进行**SQL安全净化 (Sanitize)**，移除空格、特殊字符，例如转换为 "Q1\_Sales"。
        \* 将净化后的Sheet名与上一步生成的`dataSourceId`组合，形成一个全局唯一的表名，例如: `file_ds-xyz-789_Q1_Sales`。这可以有效避免不同文件或Sheet之间的命名冲突。
        b. **推断列定义 (Infer Column Definitions)**:
        \* 读取Sheet的**第一行**作为表头。每个单元格的值将作为列名（同样需要进行SQL安全净化）。
        \* **类型推断 (Type Inference)** (可选但推荐): 检查每个列的前N行（如100行）数据，以推断该列最合适的数据类型（`INTEGER`, `REAL`, `TEXT`）。`TEXT`是所有情况下的安全默认选项。
        c. **执行DDL**: 动态构建`CREATE TABLE` SQL语句，并通过JDBC在核心SQLite数据库中创建这张表。

5.  **批量加载数据 (Batch Load Data)**:

      * 从Sheet的第二行开始，遍历所有数据行。
      * 使用**JDBC Batch Updates**来提升性能。将`INSERT`语句添加到批处理中（`PreparedStatement.addBatch()`），每累计到一定数量（如1000条）或遍历完成后，执行一次`executeBatch()`。这远比逐条插入高效。

6.  **资源清理 (Resource Cleanup)**:

      * 在`try-with-resources`块中处理文件流和`Workbook`对象，确保它们在处理完毕或发生异常时都能被正确关闭。

7.  **返回结果 (Return Result)**:

      * 在所有Sheet都成功加载后，构建并返回`FileLoadResult`对象，其中包含了本次操作的摘要信息。

#### **4. 当前实现存在的问题**

**4.1. 数据库锁定问题**

**问题描述**：
  * SQLite数据库在高并发访问时容易出现锁定问题
  * 多个文件同时上传时可能导致`database is locked`错误
  * 长时间运行的剖析任务可能阻塞文件加载操作

**当前缓解措施**：
  * 已在连接配置中添加`PRAGMA busy_timeout = 30000`
  * 启用WAL模式（`PRAGMA journal_mode = WAL`）提高并发性能
  * 设置`PRAGMA synchronous = NORMAL`平衡性能和数据安全

**4.2. 文件类型支持限制**

**问题描述**：
  * 当前主要支持Excel和CSV格式，对其他格式支持有限
  * 缺乏对复杂Excel特性的支持（如公式、图表、多级表头）
  * 大文件处理时内存消耗较高

**4.3. 元数据管理不完善**

**问题描述**：
  * 文件到表的映射关系缺乏持久化存储
  * 缺乏文件版本管理和更新机制
  * 表名生成策略可能导致冲突

**4.4. 错误处理和恢复机制**

**问题描述**：
  * 文件加载失败时缺乏回滚机制
  * 部分Sheet加载失败时的处理策略不明确
  * 缺乏详细的错误诊断信息

#### **5. 优化建议**

**5.1. 数据库架构优化**

**连接池管理**：
  * 实现专门的SQLite连接池，避免频繁创建和关闭连接
  * 采用读写分离策略，使用多个数据库文件分散负载
  * 考虑引入分布式数据库或内存数据库作为缓冲层

**事务管理**：
  * 实现更细粒度的事务控制，减少锁定时间
  * 采用批量提交策略，提高数据加载效率
  * 实现事务重试机制，自动处理临时锁定问题

**5.2. 文件处理能力增强**

**流式处理**：
  * 实现真正的流式文件处理，支持超大文件加载
  * 采用分块读取和处理策略，降低内存占用
  * 实现断点续传机制，支持大文件的可靠传输

**格式扩展**：
  * 设计可插拔的文件解析器架构
  * 支持更多文件格式（JSON、XML、Parquet、ORC等）
  * 实现智能格式检测和自动转换

**5.3. 元数据管理完善**

**映射关系持久化**：
  * 设计专门的元数据表存储文件到表的映射关系
  * 实现文件指纹机制，支持增量更新和版本管理
  * 提供元数据查询和管理API

**表名管理**：
  * 实现更智能的表名生成策略，避免冲突
  * 支持用户自定义表名和命名规则
  * 提供表名重命名和清理功能

**5.4. 监控和诊断**

**性能监控**：
  * 实现文件加载性能指标收集
  * 提供实时的加载进度和状态监控
  * 建立性能基线和异常告警机制

**错误诊断**：
  * 实现详细的错误日志和诊断信息
  * 提供错误恢复和重试机制
  * 建立错误分类和处理策略

#### **6. 数据结构定义 (DTOs)**

  * **`FileLoadResult` (DTO)**

      * 成功处理文件上传后，返回给API调用者的结果对象。
      * **结构定义**:
        ```java
        public class FileLoadResult {
            private String dataSourceId; // 为此文件生成的DataSource唯一ID
            private String originalFileName; // 上传的原始文件名
            private long fileSize; // 文件大小（字节）
            private List<LoadedTableInfo> loadedTables; // 成功加载的Sheet信息列表

            // Constructors, Getters, Setters
        }
        ```

  * **`LoadedTableInfo` (sub-DTO)**

      * `FileLoadResult`的内嵌对象，描述了单个Sheet的加载情况。
      * **结构定义**:
        ```java
        public class LoadedTableInfo {
            private String sheetName; // Excel中的原始Sheet名称
            private String tableName; // 在SQLite中生成的对应表名
            private long rowCount; // 从该Sheet加载的数据行数
            private List<String> columns; // 从表头解析出的列名列表

            // Constructors, Getters, Setters
        }
        ```

#### **7. API 端点**

由`FileController`暴露以下RESTful API：

| Method | Path | Request `Content-Type` | 描述 |
| :--- | :--- | :--- | :--- |
| `POST` | `/files/upload` | `multipart/form-data` | 上传Excel文件进行处理和加载。请求体包含一个名为`file`的文件部分和一个名为`dataSourceName`的文本部分。 |